{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a7ec5a",
   "metadata": {},
   "source": [
    "Image Classification with the MNIST Dataset\n",
    "\n",
    "x_train: Images used for training the neural network\n",
    "y_train: Correct labels for the x_train images, used to evaluate the model's predictions during training\n",
    "x_valid: Images set aside for validating the performance of the model after it has been trained\n",
    "y_valid: Correct labels for the x_valid images, used to evaluate the model's predictions after it has been trained\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1027660",
   "metadata": {},
   "source": [
    "Loading the Data Into Memory (with Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a69d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#With the mnist module, we can load the MNIST data, already partitioned into images and labels for both training and validation\n",
    "# the data, split between train and validation sets\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfebde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploring the MNIST Data\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "x_train.dtype\n",
    "x_train.min()\n",
    "x_train.max()\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = x_train[0]\n",
    "plt.imshow(image, cmap='gray')\n",
    "#In this way we can now see that this is a 28x28 pixel image of a 5\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Data for Training\n",
    "# 2-dimensional image (in our case 28x28 pixels)\n",
    "#we're going to simplify things to start and reshape each image into a single array of 784 continuous pixels (note: 28x28 = 784)\n",
    "#This is also called flattening the image.\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_valid = x_valid.reshape(10000, 784)\n",
    "x_train.shape\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the Image Data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255 \n",
    "#We can now see that the values are all floating point values between 0.0 and 1.0\n",
    "x_train.dtype\n",
    "x_train.min()\n",
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45a037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorically Encoding the Labels\n",
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)\n",
    "#Here are the first 10 values of the training labels, which you can see have now been categorically encoded\n",
    "y_train[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1afc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the Model\n",
    "\n",
    "#With the data prepared for training, it is now time to create the model that we will train with the data\n",
    "#This first basic model will be made up of several layers and will be comprised of 3 main parts:\n",
    "\n",
    "#1)An input layer, which will receive data in some expected format\n",
    "\n",
    "#2)Several hidden layers, each comprised of many neurons.\n",
    "#Each neuron will have the ability to affect the network's guess with its weights, which are values that will be updated over many iterations as the network gets feedback on its performance and learns\n",
    "\n",
    "#3)An output layer, which will depict the network's guess for a given image\n",
    "\n",
    "#Instantiating the Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Creating the Input Layer\n",
    "\n",
    "\n",
    "#Next, we will add the input layer. This layer will be densely connected, meaning that each neuron in it, and its weights, will affect every neuron in the next layer\n",
    "#To do this with Keras, we use Keras's Dense layer class.\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#The units argument specifies the number of neurons in the layer\n",
    "#relu activation function that will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function.\n",
    "#The input_shape value specifies the shape of the incoming data which in our situation is a 1D array of 784 values\n",
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))\n",
    "\n",
    "\n",
    "#Creating the Hidden Layer\n",
    "model.add(Dense(units = 512, activation='relu'))\n",
    "\n",
    "#Creating the Output Layer\n",
    "model.add(Dense(units = 10, activation='softmax'))\n",
    "#activation function softmax which will result in each of the layer's values being a probability between 0 and 1 \n",
    "\n",
    "# Summarizing the Model\n",
    "# which will print a readable summary of a model\n",
    "model.summary()\n",
    "\n",
    "#Compiling the Model \n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#loss function which will be used for the model to understand how well it is performing during training\n",
    "#We also specify that we would like to track accuracy while the model trains\n",
    "\n",
    "#Training the Model\n",
    "#arguments:\n",
    "\n",
    "#The training data\n",
    "#The labels for the training data\n",
    "#The number of times it should train on the entire training dataset (called an epoch)\n",
    "#The validation or test data, and its labels\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
    ")\n",
    "\n",
    "\n",
    "#Observing Accuracy\n",
    "#The accuracy quickly reached close to 100%"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
